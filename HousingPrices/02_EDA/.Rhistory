row.names(mtcars)
?mtcars
write.csv(mtcars,file="mtcars.csv")
getwd()
library(installr)
install.R()
acs_url <- 'http://s3.amazonaws.com/assets.datacamp.com/production/course_810/AC_Survey_Subset.RData'
?load
load(url(acs_url))
head(AC_Survey_Subset,20)
library(dplyr)
AC_Survey_Subset <- tbl_df(AC_Survey_Subset)
?filter
AC_Survery_Subset %>% na.omit() %>% filter(SCHL=c(21,22,24)) %>% group_by(SCHL)
AC_Survey_Subset %>% na.omit() %>% filter(SCHL=c(21,22,24)) %>% group_by(SCHL)
AC_Survey_Subset %>% na.omit() %>% filter(SCHL %in% c(21,22,24)) %>% group_by(SCHL)
AC_Survey_Subset_Cleaned <- AC_Survey_Subset %>%
na.omit() %>% filter(SCHL %in% c(21,22,24)) %>% group_by(SCHL)
degree_holders <- summarize(AC_Survey_Subset_Cleaned)
degree_holders
degree_holders <- summarize(AC_Survey_Subset_Cleaned,n())
degree_holders
data.clean <- AC_Survey_Subset %>%
na.omit() %>% filter(SCHL %in% c(21,22,24)) %>% group_by(SCHL)
degree.codes <- data.frame(SCHL=c(21,22,24),Degree=c('Bachelor,Masters,Doctorate'))
## Count the number of Bachelor, Master, and PhD holders
degree.holders <- summarize(AC_Survey_Subset_Cleaned,n())
?inner_join
degree.holders.2 <- inner_join(degree.holders,degree.codes,by=SCHL)
degree.holders.2 <- inner_join(degree.holders,degree.codes,by='SCHL')
degree.holders <- summarize(AC_Survey_Subset_Cleaned,count=n())
degree.codes <- data.frame(SCHL=c(21,22,24),Degree=c('Bachelor,Masters,Doctorate'))
## Count the number of Bachelor, Master, and PhD holders
degree.holders <- summarize(AC_Survey_Subset_Cleaned,count=n())
## Join the two tables into degree.holders.2
degree.holders.2 <- inner_join(degree.holders,degree.codes,by='SCHL')
sys.info
sys.info()
??sys
Sys.info()
R.Version()
install.R()
installR()
?install
??install
library(installr)
install.R()
R.Version()
?system.time
#### Part 1: The Standard Method ####
##  Build an example where even and odd variables are bringing in noisy images of two different
## signals.
mkData <- function(n) {
for(group in 1:10) {
## y is the sum of two effects yA and yB
yA <- rnorm(n)
yB <- rnorm(n)
if(group == 1) {
d <- data.frame(y = yA + yB + rnorm(n))
code <- 'x'
} else {
code <- paste0('noise', group - 1)
}
yS <- list(yA,yB)
## These variables are correlated with y in group 1, but only to each other (and not y) in
## other groups
for(i in 1:5) {
vi <- yS[[1 + (i %% 2)]] + rnorm(nrow(d))
d[[paste(code, formatC(i, width = 2, flag = 0),sep = '.')]] <- ncol(d) * vi
}
}
d
}
## Make data
set.seed(23525)
dTrain <- mkData(1000)
dTest  <- mkData(1000)
summary(dTrain, c('y', 'x.01', 'x.02', 'noise.01', 'noise1.02'))
summary(dTrain[, c('y', 'x.01', 'x.02', 'noise.01', 'noise1.02')])
summary(dTrain[, c('y', 'x.01', 'x.02', 'noise1.01', 'noise1.02')])
##  Build an example where even and odd variables are bringing in noisy images of two different
## signals.
mkData <- function(n) {
for(group in 1:10) {
## y is the sum of two effects yA and yB
yA <- rnorm(n)
yB <- rnorm(n)
if(group == 1) {
d <- data.frame(y = yA + yB + rnorm(n))
code <- 'x'
} else {
code <- paste0('noise', group - 1)
}
yS <- list(yA,yB)
## These variables are correlated with y in group 1, but only to each other (and not y) in
## other groups
for(i in 1:5) {
vi <- yS[[1 + (i %% 2)]] + rnorm(nrow(d))
d[[paste(code, formatC(i, width = 2, flag = 0),sep = '.')]] <- ncol(d) * vi
}
}
d
}
## Make data
set.seed(23525)
dTrain <- mkData(1000)
dTest  <- mkData(1000)
summary(dTrain[, c('y', 'x.01', 'x.02', 'noise1.01', 'noise1.02')])
#==================================================================================================#
#### Global Setup ####
## Principal Components Regression Series from www.win-vector.com
#==================================================================================================#
#### Part 1: The Standard Method ####
## Build an example where even and odd variables are bringing in noisy images of two different
## signals.
mkData <- function(n) {
for(group in 1:10) {
## y is the sum of two effects yA and yB
yA <- rnorm(n)
yB <- rnorm(n)
if(group == 1) {
d <- data.frame(y = yA + yB + rnorm(n))
code <- 'x'
} else {
code <- paste0('noise', group - 1)
}
yS <- list(yA,yB)
## These variables are correlated with y in group 1, but only to each other (and not y) in
## other groups
for(i in 1:5) {
vi <- yS[[1 + (i %% 2)]] + rnorm(nrow(d))
d[[paste(code, formatC(i, width = 2, flag = 0),sep = '.')]] <- ncol(d) * vi
}
}
d
}
## Make data
set.seed(23525)
dTrain <- mkData(1000)
dTest  <- mkData(1000)
summary(dTrain[, c('y', 'x.01', 'x.02', 'noise1.01', 'noise1.02')])
## Ideal Situation
goodVars <- colnames(dTrain)[grep('^x.', colnames(dTrain))]
dTrainIdeal <- dTrain[ , c('y', goodVars)]
dTestIdeal  <- dTest[ , c('y', goodVars)]
dmTrainIdeal <- as.matrix(dTrainIdeal[ , goodVars])
princIdeal <- prcomp(dmTrainIdeal, center = TRUE, scale = TRUE)
?prcomp
head(dTrainIdeal)
head(dmTrainIdeal)
?extractProjection
rot5Ideal <- extractProjection(5, princIdeal)
extractProjection <- function(ndim,princ) {
# pull off the rotation.
proj <- princ$rotation[,1:ndim]
# sign was arbitrary, so flip in convenient form
for(i in seq_len(ndim)) {
si <- sign(mean(proj[,i]))
if(si!=0) {
proj[,i] <- proj[,i]*si
}
}
proj
}
rsq <- function(x,y) {
1 - sum((y - x) ^ 2) / sum((y - mean(y)) ^ 2)
}
rot5Ideal <- extractProjection(5, princIdeal)
rot5Ideal
princIdeal$rotation
proj <- princIdeal$rotation[ , 1:5]
proj
seq_len(5)
sign(mean(proj[,1]))
sign(mean(proj[,2]))
sign(mean(proj[,3]))
sign(mean(proj[,4]))
sign(mean(proj[,5]))
proj
rot5Ideal
## Prepare the data to plot the variable loadings
rotfIdeal <- as.data.frame(rot5Ideal)
rotfIdeal$varName <- row.names(rotfIdeal)
library(ggplot2)
library(plyr)
library(dplyr)
barbell_plot = function(frame, xvar, ymin, ymax, colorvar=NULL) {
if(is.null(colorvar)) {
gplot = ggplot(frame, aes_string(x=xvar))
} else {
gplot = ggplot(frame, aes_string(x=xvar, color=colorvar))
}
gplot + geom_point(aes_string(y=ymin)) +
geom_point(aes_string(y=ymax)) +
geom_linerange(aes_string(ymin=ymin, ymax=ymax)) +
ylab("value")
}
dotplot_identity = function(frame, xvar, yvar, colorvar=NULL) {
if(is.null(colorvar)) {
gplot = ggplot(frame, aes_string(x=xvar, y=yvar, ymax=yvar))
} else {
gplot = ggplot(frame,
aes_string(x=xvar, y=yvar, ymax=yvar,
color=colorvar))
}
gplot + geom_point() + geom_linerange(aes(ymin=0))
}
library(reshape2)
?melt
library(tidyr)
install.packages('tidry')
install.packages('tidyr')
library(tidyr)
?gather
?melt
??dplyr
browseVignettes(package = 'dplyr')
rotfIdeal
roflongIdeal <- melt(rotfIdeal,
id.vars = starts_with('PC'),
variable.name = 'PC',
value.name = 'loadings')
roflongIdeal <- melt(rotfIdeal,
id.vars = colnames(rotfIdeal)[grep('PC', colnames(rotfIdeal))],
variable.name = 'PC',
value.name = 'loadings')
roflongIdeal
rotflongIdeal = gather(rotfIdeal, "PC", "loading",
starts_with("PC"))
rotflongIdeal
rotflongIdeal <- melt(rotfIdeal,
id.vars = c(colnames(rotfIdeal)[grep('PC', colnames(rotfIdeal))], 'varName'),
variable.name = 'PC',
value.name = 'loadings')
rotflongIdeal
melt(rotfIdeal, varName ~ .)
melt(rotfIdeal, . ~ varName)
rotflongIdeal <- melt(rotfIdeal,
id.vars = 'varName',
variable.name = 'PC',
value.name = 'loadings')
rotflongIdeal
rotflongIdeal = gather(rotfIdeal, "PC", "loading",
starts_with("PC"))
rotflongIdeal
dotplot_identity(frame = data.frame(pc = 1:length(princIdeal$sdev),
magnitude = princIdeal$sdev),
xvar = 'pc', yvar = 'magnitude') +
ggtitle('Ideal case: Magnitudes of singular values')
rotflongIdeal <- melt(rotfIdeal, id.vars = 'varName', variable.name = 'PC', value.name = 'loading')
rotflongIdeal$vartype = ifelse(grepl('noise', rotflongIdeal$varName), 'noise', 'signal')
rotflongIdeal
## Ideal Situation
goodVars <- colnames(dTrain)[grep('^x.', colnames(dTrain))]
dTrainIdeal <- dTrain[ , c('y', goodVars)]
dTestIdeal  <- dTest[ , c('y', goodVars)]
## Do the PCA
dmTrainIdeal <- as.matrix(dTrainIdeal[ , goodVars])
princIdeal <- prcomp(dmTrainIdeal, center = TRUE, scale = TRUE)
## Extract the principal components
rot5Ideal <- extractProjection(5, princIdeal)
## Prepare the data to plot the variable loadings
rotfIdeal <- as.data.frame(rot5Ideal)
rotfIdeal$varName <- row.names(rotfIdeal)
rotflongIdeal <- melt(rotfIdeal, id.vars = 'varName', variable.name = 'PC', value.name = 'loading')
rotflongIdeal$vartype = ifelse(grepl('noise', rotflongIdeal$varName), 'noise', 'signal')
dotplot_identity(rotlongIdeal, 'varName', 'loading', 'vartype') +
facet_wrap( ~ PC, nrow = 1) +
coord_flip() +
ggtitle('x scaled variable loadings, first 5 principal components') +
scale_color_manual(values = c('noise' = '#d95f02', 'signal' = '#1b9e77')
)
dotplot_identity(rotflongIdeal, 'varName', 'loading', 'vartype') +
facet_wrap( ~ PC, nrow = 1) +
coord_flip() +
ggtitle('x scaled variable loadings, first 5 principal components') +
scale_color_manual(values = c('noise' = '#d95f02', 'signal' = '#1b9e77'))
?%*%
projectedTrainIdeal <- as.data.frame(dmTrainIdeal %*% extractProjection(2, princIdeal),
stringsAsFactors = FALSE)
projectedTrainIdeal$y <- dTrain$y
ScatterHistN(projectedTrainIdeal, 'PC1', 'PC2', 'y',
'Ideal Data projected to first two principal components')
devtools::install_github('WinVector/WVPlots', build_vignettes = TRUE)
library(WVPlots) #devtools::install_github('WinVector/WVPlots', build_vignettes = TRUE)
ScatterHistN
?ScatterHistN
ScatterHist(projectedTrainIdeal, 'PC1', 'PC2', 'y',
'Ideal Data projected to first two principal components')
library(WVPlots)
?stringr
unloadNamespace(stringr)
unloadNamespace('stringr')
devtools::install_github('WinVector/WVPlots', build_vignettes = TRUE)
library(WVPlots) #devtools::install_github('WinVector/WVPlots', build_vignettes = TRUE)
library(installr)
library(install.R)
install.packages('installr')
install.R()
library(installr)
install.R()
library('installr')
install.R()
?glm
library(glmnet)
?glmnet.predict
?predict.glmnet
library(data.table)
fread('C:/Users/michael.hoyer/Desktop/GPIfeatures.csv')
install.packages('tidyr')
library(tidyr)
??tidyr
gpi.summ <- fread('C:/Users/michael.hoyer/Desktop/GPIfeatures.csv')
head(gpi.summ)
gpi.modelframe <- gpi.summ %>% select(MemberID, FeatureName, FeatureValue) %>% spread(key = FeatureName, value = FeatureValue)
library(plyr)
library(dplyr)
gpi.modelframe <- gpi.summ %>% select(MemberID, FeatureName, FeatureValue) %>% spread(key = FeatureName, value = FeatureValue)
head(gpi.modelframe)
summary(gpi.modelframe)
fread('C:/Users/michael.hoyer/Desktop/Mortality_2015_IAS_rxfills.csv',data.table = FALSE)
library(data.table)
fread('C:/Users/michael.hoyer/Desktop/Mortality_2015_IAS_rxfills.csv',data.table = FALSE)
library(data.table)
fread('C:/Users/michael.hoyer/Desktop/Mortality_2015_IAS_rxfills.csv')
proc.time()
proc.time()[1]
proc.time()[3]
proc.time()[[3]]
proc.time()[[3]]
proc.time()[[3]]
proc.time()[[3]]
proc.time()[[3]]
proc.time()[[3]]
tme <- proc.time()
install.packages('dplyr')
library(DiagrammeR)
install.packages('dplyr')
library(DiagrammeR)
library(installr)
install.R()
tmp <- installed.packages()
tmp
installed <- as.vector(tmp[is.na(tmp[,"Priority"]), 1])
head(installed)
installed
#==================================================================================================#
## Project:     PM @ Lunchtime - Housing Prices
## Purpose:     For learning and improving predictive modeling expertise
## Authored by: Mike Hoyer
## Date:        03/29/2017
##
## Updates:
##   -
##
#==================================================================================================#
#==================================================================================================#
#### Global Setup ####
#==================================================================================================#
## Set working directory
setwd('M:/Predictive Modeling/PM @ Lunchtime/HousingPrices')
## Load necessary packages
library(data.table)   # fread for quick data loading
library(plyr)
library(dplyr)        # data manipulation
library(tidyr)        # data manipulation
library(ggplot2)      # plots
library(Rmisc)        # multiplot
library(glmnet)       # regularized glms
library(randomForest) # random forest alg
library(xgboost)      # xgboost
library(caret)        # createDataPartition
## Set random seed
set.seed(12)
## Read in data
train.data <- fread('train.csv', stringsAsFactors = TRUE, data.table = FALSE)
str(train.data)
?fread
head(train.data)
## Graph the target variable SalePrice
ggplot(train.data, aes(x = SalePrice))+
geom_histogram(bins = 20, alpha = 0.5, color = 1, fill = 4)
## Graph the log target variable SalePrice
## note: data taking the log seems to remove skew, we can use this in modeling
ggplot(train.data, aes(x = log(SalePrice)))+
geom_histogram(bins = 20, alpha = 0.5, color = 1, fill = 4)
str(train.data %>%
select(BsmtFullBath, BsmtHalfBath, FullBath, KitchenAbvGr, HalfBath, TotRmsAbvGrd, GarageCars,
BedroomAbvGr, Fireplaces, MoSold, YrSold))
unique(train.data$Fireplaces)
cont.to.cat <- c('BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'KitchenAbvGr', 'HalfBath',
'TotRmsAbvGrd', 'GarageCars', 'BedroomAbvGr', 'Fireplaces', 'MoSold', 'YrSold')
train.data[, cont.to.cat] <- lapply(train.data[, cont.to.cat], FUN = as.factor)
str(train.data %>%
select(BsmtFullBath, BsmtHalfBath, FullBath, KitchenAbvGr, HalfBath, TotRmsAbvGrd, GarageCars,
BedroomAbvGr, Fireplaces, MoSold, YrSold))
classes <- sapply(train.data, FUN = class)
class(train.data)
class(train.data$Id)
unique(classes)
cont.cols <- names(train.data)[classes == 'integer']
cont.cols <- cont.cols[-which(cont.cols %in% c('Id', 'SalePrice'))]
cont.cols
## Plot distribution for each continous variable
cont.plots <- list()
for (col in cont.cols) {
## Genericize smaller data frame for plotting
plot.data <- data.frame(x = train.data[[col]], y = train.data$SalePrice)
plot.data <- plot.data[!is.na(plot.data$x), ]
## Create plot
p <- ggplot(plot.data, aes(x = x)) +
geom_histogram(bins = 20, alpha = 0.5, color = 1, fill = 4) +
xlab(col)
## Store plot in plot list
cont.plots <- c(cont.plots, list(p))
}
suppressWarnings(multiplot(plotlist = cont.plots[ 1: 6], cols = 3))
suppressWarnings(multiplot(plotlist = cont.plots[ 7:12], cols = 3))
suppressWarnings(multiplot(plotlist = cont.plots[13:18], cols = 3))
suppressWarnings(multiplot(plotlist = cont.plots[19:24], cols = 3))
suppressWarnings(cont.plots[25])
## Plot relationship to SalePrice for each continous variable
cont.plots <- list()
for (col in cont.cols) {
## Genericize smaller data frame for plotting
plot.data <- data.frame(x = train.data[[col]], y = train.data$SalePrice)
plot.data <- plot.data[!is.na(plot.data$x), ]
## Create plot
p <- ggplot(plot.data, aes(x = x, y = log1p(y))) +
geom_point(alpha = 0.5) +
geom_jitter() +
geom_smooth() +
xlab(col) +
ylab('SalePrice')
## Store plot in plot list
cont.plots <- c(cont.plots, list(p))
}
suppressWarnings(multiplot(plotlist = cont.plots[ 1: 6], cols = 3))
suppressWarnings(multiplot(plotlist = cont.plots[ 7:12], cols = 3))
suppressWarnings(multiplot(plotlist = cont.plots[13:18], cols = 3))
suppressWarnings(multiplot(plotlist = cont.plots[19:24], cols = 3))
suppressWarnings(cont.plots[25])
unique(train.data$OverallCond)
unique(train.data$OverallQual)
unique(train.data$MSSubClass)
View(train.data %>% filter(`1stFlrSF` > 4000))
#==================================================================================================#
#### Categorical Plots ####
#==================================================================================================#
cat.cols <- names(train.data)[classes == 'factor']
## Plot distribution for each categorical variable
cat.plots <- list()
for (col in cat.cols) {
## Genericize smaller data frame for plotting
plot.data <- data.frame(x = train.data[[col]], y = train.data$SalePrice)
plot.data <- plot.data[!is.na(plot.data$x), ]
## Create plot
p <- ggplot(plot.data, aes(x = x)) +
geom_bar(aes(y = ..count.. / sum(..count..)), alpha = 0.5, color = 1, fill = 4) +
ylab('Proportion') +
xlab(col)
## Store plot in plot list
cat.plots <- c(cat.plots, list(p))
}
suppressWarnings(multiplot(plotlist = cat.plots[ 1: 9], cols = 3))
suppressWarnings(multiplot(plotlist = cat.plots[10:18], cols = 3))
suppressWarnings(multiplot(plotlist = cat.plots[19:27], cols = 3))
suppressWarnings(multiplot(plotlist = cat.plots[28:36], cols = 3))
suppressWarnings(multiplot(plotlist = cat.plots[37:45], cols = 3))
suppressWarnings(multiplot(plotlist = cat.plots[46:54], cols = 3))
## Plot relationship to SalePrice for each categorical variable
cat.plots <- list()
for (col in cat.cols) {
## Genericize smaller data frame for plotting
plot.data <- data.frame(x = train.data[[col]], y = train.data$SalePrice)
plot.data <- plot.data[!is.na(plot.data$x), ]
## Create plot
p <- ggplot(plot.data, aes(x = x, y = log1p(y))) +
geom_boxplot(alpha = 0.5, color = 1, fill = 4) +
ylab('Proportion') +
xlab(col)
## Store plot in plot list
cat.plots <- c(cat.plots, list(p))
}
suppressWarnings(multiplot(plotlist = cat.plots[ 1: 9], cols = 3))
suppressWarnings(multiplot(plotlist = cat.plots[10:18], cols = 3))
suppressWarnings(multiplot(plotlist = cat.plots[19:27], cols = 3))
suppressWarnings(multiplot(plotlist = cat.plots[28:36], cols = 3))
suppressWarnings(multiplot(plotlist = cat.plots[37:45], cols = 3))
suppressWarnings(multiplot(plotlist = cat.plots[46:54], cols = 3))
?corr
?cor
library(ggcorrplot)
install.packages('ggcorrplot')
corr <- round(cor(num.col), 1)
library(ggcorrplot)
train.matrix <- data.matrix(train.data[, cont.cols]) * 1
corr <- round(cor(train.matrix), 1)
library(ggcorrplot)
ggcorrplot(corr, hc.order = TRUE, type = "lower", lab = TRUE)
corr
plot(corr)
library(Hmsic)
library(Hmisc)
rcorr(train.matrix, type = 'pearson')
plot(rcorr(train.matrix, type = 'pearson'))
install.packages('corrplot')
corrplot(corr)
library(corrplot)
corrplot(corr)
corrplot(rcorr(train.matrix, type = 'pearson'))
View(corr)
